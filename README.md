# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
This dataset contains data about marketing campaign information for a bank to get clients to subscribe to a banking deposit. We seek to predict the outcome variable (y) which is the client saying yes to subscribing to a banking deposit. 

The best performing model from the AutoML run was a voting ensamble.  

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

Initial Setup
- Retrieve workspace from .from_config()
- Create an experiment with name 'udacity-project'
- Turn on logging 

Compute Configuration
- Create a compute cluster, set config to VM Size of Standard D2 V2 with max nodes 4
- Create compute target using the cluster, unique name and workspace
- Wait for completion and show the output

Training Script (train.py)
- Import the data using Tabular Dataset Factor
- Clean up the data
- Split up the data into train and test data sets
- Use a logistic regression model for classification

Hyperdrive Configuration
- Create parameter sampling by using Random Parameter Sampling of 'C' and 'max_iter' which are the params in our python training script. 
- Create a early termination policy with Bandit Policy using slack factor, evaluation interval and delay evaluation
- Create SKLearn estimator by specificying the entry script train.py, our cluster name and the directory of the script
- Now use the ps, est and policy specified in previous steps and create the hyper drive config with additional parameters of primary metric of Accuracy, a metric goal of Maximize, max total runs and max concurrent runs.

Now we submit our hyper run by submitting the hyperdrive config to our experiment. Display the RunDetails of the hyper run to show info while running.

Next we figure out what the best run is and display more information for us to view, then register the best model as 'best-hyperdriveâ€™.

Parameter Sample
I used RandomParameterSampling as it supports discrete and continuous hyperparameters. It supports early termination of low-performance runs and supports early stopping policies. In random sampling, the hyperparameter (C : smaller values specify stronger regularization, max_iter : maximum number of iterations taken for the solvers to converge) values are randomly selected from the defined search space.

Early Stopping Policy
The early stopping policy I chose was BanditPolicy because it is based on slack factor and evaluation interval. Bandit terminates runs where the primary metric is not within the specified slack factor compared to the best performing run.


## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

Initial Setup
- We already have the workspace

Data Setup
- Retreive data set from TabularDatasetFactory from .csv location
- Clean the data and create sets for training and testing

Auto ML Configuration
- Create AutoMLConfig using timeout, task of 'classification', primary metric of accuracy, set the training data and cross validations to 5

Create Auto Run
- Set up experiment 'udacity-project-automl' using the workspace
- Submit the automl config using our designated experiment with show output to true to view the info

Some of the information generated by the output where Gaurdrails

****************************************************************************************************
DATA GUARDRAILS: 

TYPE:         Class balancing detection
STATUS:       ALERTED
DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.
              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData
DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.
+---------------------------------+---------------------------------+--------------------------------------+
|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|
+=================================+=================================+======================================+
|2470                             |1                                |22076                                 |
+---------------------------------+---------------------------------+--------------------------------------+

****************************************************************************************************

TYPE:         Missing feature values imputation
STATUS:       PASSED
DESCRIPTION:  No feature missing values were detected in the training data.
              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization

****************************************************************************************************

TYPE:         High cardinality feature detection
STATUS:       PASSED
DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.
              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization

****************************************************************************************************

The Models created by the AutoML Run used the folowing Algorithms
Voting Enemble
WaxAbsScaler, XGBoostClassifier
StandardScalerWrapper, XGBoostClassifier
MaxAbsSCaler, LightGBM
StackEnsemble
StandardScalerWrapper, Logisitric Regression
MinMaxScaler, SGD

The Voting Enemble had the best Accuracy


## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

Both the approaches follow simlar steps but the differerence is in the configuration. The first approach our ML model is fixed and we use hyperdrive to find optimal hyperparams while in second approach dif models are generated with their own optimal hyperparam values and the best model is then selected. The first approach took around 10 - 15 min and accuracy was around 0.914 and the automl approach took much longer 25 - 30 min and only had a slightly better accuracy around 0.917.

The AutoML results in better accuracy but takes longer to find the better result. It combines multiple ML algorithms so it makes sence that it will find a better result over time.  

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

Some potential risks and best practices to mitigate can be found here: https://docs.microsoft.com/en-us/azure/machine-learning/concept-manage-ml-pitfalls

Identify over-fitting with the data
The best way to prevent over-fitting is to follow ML best-practices including:

Using more training data, and eliminating statistical bias
Preventing target leakage
Using fewer features
Regularization and hyperparameter optimization
Model complexity limitations
Cross-validation

Handle imbalanced Data
Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.

As part of its goal of simplifying the machine learning workflow, automated ML has built in capabilities to help deal with imbalanced data such as,

A weight column: automated ML supports a column of weights as input, causing rows in the data to be weighted up or down, which can be used to make a class more or less "important".

The algorithms used by automated ML detect imbalance when the number of samples in the minority class is equal to or fewer than 20% of the number of samples in the majority class, where minority class refers to the one with fewest samples and majority class refers to the one with most samples. Subsequently, AutoML will run an experiment with sub-sampled data to check if using class weights would remedy this problem and improve performance. If it ascertains a better performance through this experiment, then this remedy is applied.

Use a performance metric that deals better with imbalanced data. For example, the AUC_weighted is a primary metric that calculates the contribution of every class based on the relative number of samples representing that class, hence is more robust against imbalance.


## Proof of cluster clean up
Deleted in code

# azure-ml-proj
